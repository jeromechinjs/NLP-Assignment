{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Product Comment Sentiment Analysis\n",
    "\n",
    "**Resources**\n",
    "*   https://www.geeksforgeeks.org/what-is-sentiment-analysis/ (intro)\n",
    "*   https://www.nltk.org/api/nltk.tokenize.html (tokenize - separate sentence into words)\n",
    "*   https://youtu.be/9p1KYtYAus8 (vader lexicon tutorial - for sentiment analysis)\n",
    "*   dataset (#56 from https://www.nltk.org/nltk_data/)\n",
    "*   dataset downloaded from https://www.kaggle.com/datasets/mdwaquarazam/headphone-dataset-review-analysis\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<br>\n",
    "Documents (bg study, methods etc will do later)\n",
    "\n",
    "> Step 1: Get data (csv file)\n",
    "\n",
    "> Step 2: Pre-processing. Tokenize, Lemmatize, remove stopwords, punctuations etc, then do sentiment analysis\n",
    "\n",
    "> Step 3: Count vectorizer (frequency each words appeared), then identify similarity (use cosine similarity equation, correlation etc.)\n",
    "\n",
    "> Step 4: each of us will choose our preferred method (bayes, knn, k-means)\n",
    "\n",
    "> Step 5: compare the results (from using different methods)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: click in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.54.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.1.2; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n",
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\OneDrive - Tunku Abdul Rahman University College\\Software Engineering\\Year 2\\Sem 3\\AI\\NLP-Assignment\\AI-Assignment-NLP.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m \u001b[39m# python's 're' module to create empty strings with pattern that matches pucnctuation marks\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstring\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m nltk\u001b[39m.\u001b[39;49mdownload(\u001b[39m'\u001b[39;49m\u001b[39mall\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m site\u001b[39m.\u001b[39mgetsitepackages() \u001b[39m# to ourpur current path, we imported site, and getsitepackages()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\downloader.py:777\u001b[0m, in \u001b[0;36mDownloader.download\u001b[1;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow\u001b[39m(s, prefix2\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    769\u001b[0m     print_to(\n\u001b[0;32m    770\u001b[0m         textwrap\u001b[39m.\u001b[39mfill(\n\u001b[0;32m    771\u001b[0m             s,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    774\u001b[0m         )\n\u001b[0;32m    775\u001b[0m     )\n\u001b[1;32m--> 777\u001b[0m \u001b[39mfor\u001b[39;00m msg \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mincr_download(info_or_id, download_dir, force):\n\u001b[0;32m    778\u001b[0m     \u001b[39m# Error messages\u001b[39;00m\n\u001b[0;32m    779\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(msg, ErrorMessage):\n\u001b[0;32m    780\u001b[0m         show(msg\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\downloader.py:637\u001b[0m, in \u001b[0;36mDownloader.incr_download\u001b[1;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(info, Collection):\n\u001b[0;32m    636\u001b[0m     \u001b[39myield\u001b[39;00m StartCollectionMessage(info)\n\u001b[1;32m--> 637\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mincr_download(info\u001b[39m.\u001b[39mchildren, download_dir, force)\n\u001b[0;32m    638\u001b[0m     \u001b[39myield\u001b[39;00m FinishCollectionMessage(info)\n\u001b[0;32m    640\u001b[0m \u001b[39m# Handle Packages (delegate to a helper function).\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\downloader.py:624\u001b[0m, in \u001b[0;36mDownloader.incr_download\u001b[1;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[39m# If they gave us a list of ids, then download each one.\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(info_or_id, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m--> 624\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_list(info_or_id, download_dir, force)\n\u001b[0;32m    625\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[39m# Look up the requested collection or package.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\downloader.py:667\u001b[0m, in \u001b[0;36mDownloader._download_list\u001b[1;34m(self, items, download_dir, force)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m     delta \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(item\u001b[39m.\u001b[39mpackages) \u001b[39m/\u001b[39m num_packages\n\u001b[1;32m--> 667\u001b[0m \u001b[39mfor\u001b[39;00m msg \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mincr_download(item, download_dir, force):\n\u001b[0;32m    668\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(msg, ProgressMessage):\n\u001b[0;32m    669\u001b[0m         \u001b[39myield\u001b[39;00m ProgressMessage(progress \u001b[39m+\u001b[39m msg\u001b[39m.\u001b[39mprogress \u001b[39m*\u001b[39m delta)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\downloader.py:642\u001b[0m, in \u001b[0;36mDownloader.incr_download\u001b[1;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[39myield\u001b[39;00m FinishCollectionMessage(info)\n\u001b[0;32m    640\u001b[0m \u001b[39m# Handle Packages (delegate to a helper function).\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 642\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_package(info, download_dir, force)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\downloader.py:680\u001b[0m, in \u001b[0;36mDownloader._download_package\u001b[1;34m(self, info, download_dir, force)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[39myield\u001b[39;00m ProgressMessage(\u001b[39m0\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[39m# Do we already have the current version?\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m status \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatus(info, download_dir)\n\u001b[0;32m    681\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m force \u001b[39mand\u001b[39;00m status \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mINSTALLED:\n\u001b[0;32m    682\u001b[0m     \u001b[39myield\u001b[39;00m UpToDateMessage(info)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\downloader.py:883\u001b[0m, in \u001b[0;36mDownloader.status\u001b[1;34m(self, info_or_id, download_dir)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    882\u001b[0m     \u001b[39mif\u001b[39;00m info\u001b[39m.\u001b[39mid \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_status_cache:\n\u001b[1;32m--> 883\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_status_cache[info\u001b[39m.\u001b[39mid] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pkg_status(info, filepath)\n\u001b[0;32m    884\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_status_cache[info\u001b[39m.\u001b[39mid]\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\downloader.py:911\u001b[0m, in \u001b[0;36mDownloader._pkg_status\u001b[1;34m(self, info, filepath)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(unzipdir):\n\u001b[0;32m    909\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSTALE\n\u001b[1;32m--> 911\u001b[0m unzipped_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39;49m(\n\u001b[0;32m    912\u001b[0m     os\u001b[39m.\u001b[39;49mstat(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(d, f))\u001b[39m.\u001b[39;49mst_size\n\u001b[0;32m    913\u001b[0m     \u001b[39mfor\u001b[39;49;00m d, _, files \u001b[39min\u001b[39;49;00m os\u001b[39m.\u001b[39;49mwalk(unzipdir)\n\u001b[0;32m    914\u001b[0m     \u001b[39mfor\u001b[39;49;00m f \u001b[39min\u001b[39;49;00m files\n\u001b[0;32m    915\u001b[0m )\n\u001b[0;32m    916\u001b[0m \u001b[39mif\u001b[39;00m unzipped_size \u001b[39m!=\u001b[39m info\u001b[39m.\u001b[39munzipped_size:\n\u001b[0;32m    917\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSTALE\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\downloader.py:912\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(unzipdir):\n\u001b[0;32m    909\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSTALE\n\u001b[0;32m    911\u001b[0m unzipped_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\n\u001b[1;32m--> 912\u001b[0m     os\u001b[39m.\u001b[39;49mstat(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(d, f))\u001b[39m.\u001b[39mst_size\n\u001b[0;32m    913\u001b[0m     \u001b[39mfor\u001b[39;00m d, _, files \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mwalk(unzipdir)\n\u001b[0;32m    914\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files\n\u001b[0;32m    915\u001b[0m )\n\u001b[0;32m    916\u001b[0m \u001b[39mif\u001b[39;00m unzipped_size \u001b[39m!=\u001b[39m info\u001b[39m.\u001b[39munzipped_size:\n\u001b[0;32m    917\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSTALE\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# install nltk (terminal line commands)\n",
    "%pip install nltk\n",
    "%pip install pandas\n",
    "\n",
    "import nltk\n",
    "import site\n",
    "import pandas as pd    # to allow us to read csv file\n",
    "import random\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize # for tokenization of words\n",
    "from nltk.stem import WordNetLemmatizer # for lemmatization\n",
    "import re # python's 're' module to create empty strings with pattern that matches pucnctuation marks\n",
    "import string\n",
    "\n",
    "nltk.download('all')\n",
    "site.getsitepackages() # to ourpur current path, we imported site, and getsitepackages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('headphone_datn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_Name    1604\n",
      "REVIEW_TITLE     1594\n",
      "Color            1604\n",
      "REVIEW_DATE      1604\n",
      "COMMENTS         1546\n",
      "RATINGS          1604\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data.head()\n",
    "total = data.count()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\OneDrive - Tunku Abdul Rahman University College\\Software Engineering\\Year 2\\Sem 3\\AI\\NLP-Assignment\\AI-Assignment-NLP.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m tokens\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m   \u001b[39m# # remove stop words\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m   \u001b[39m# filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m#data['Comments'] = data['COMMENTS'].apply(preprocess_text_function) # apply preprocess_text_function to each row in data['COMMENTS']\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(data[\u001b[39m'\u001b[39;49m\u001b[39mCOMMENTS\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(preprocess_text_function))\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:4138\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4137\u001b[0m         values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 4138\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(values, f, convert\u001b[39m=\u001b[39;49mconvert_dtype)\n\u001b[0;32m   4140\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], Series):\n\u001b[0;32m   4141\u001b[0m     \u001b[39m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m     \u001b[39m# so extension arrays can be used\u001b[39;00m\n\u001b[0;32m   4143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mpandas\\_libs\\lib.pyx:2467\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\OneDrive - Tunku Abdul Rahman University College\\Software Engineering\\Year 2\\Sem 3\\AI\\NLP-Assignment\\AI-Assignment-NLP.ipynb Cell 8\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_text_function\u001b[39m(text):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39m# regex = re.compile('[%s]' % re.escape(string.punctuation)) \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   \u001b[39m# clean_Text = re.sub('[^\\w\\s]','',text.lower()) \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   \u001b[39m# make all text into lowercase\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   \u001b[39m# remove punctuations\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m   punctuation_marks \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m re\u001b[39m.\u001b[39mescape(string\u001b[39m.\u001b[39mpunctuation)) \u001b[39m# creating an expression that matches all punctuation \u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# create pre processing function\n",
    "\n",
    "def preprocess_text_function(text):\n",
    "  # regex = re.compile('[%s]' % re.escape(string.punctuation)) \n",
    "  # clean_Text = re.sub('[^\\w\\s]','',text.lower()) \n",
    "  \n",
    "  # make all text into lowercase\n",
    "  text = text.lower()\n",
    "\n",
    "  # remove punctuations\n",
    "  \n",
    "  punctuation_marks = re.compile('[%s]' % re.escape(string.punctuation)) # creating an expression that matches all punctuation \n",
    "  cleaned_text = punctuation_marks.sub('', text) # use sub() to replace all matched punctuation patterns with an empty string\n",
    "\n",
    "  # tokenize the text \n",
    "  tokens = word_tokenize(cleaned_text)\n",
    "  return tokens\n",
    "  # # remove stop words\n",
    "  # filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "  # # lemmatize the tokens\n",
    "  # lemmatizer = WordNetLemmatizer()\n",
    "  # lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "  # #Join the tokens back into a string\n",
    "  # processed_text = ' '.join(lemmatized_tokens)\n",
    "  # return processed_text\n",
    "\n",
    "# call the function df\n",
    "\n",
    "#df = pd.DataFrame(df, columns = ['Customer_Name','REVIEW_TITLE', 'Color', 'REVIEW_DATE', 'COMMENTS', 'RATINGS'])\n",
    "\n",
    "#data['Comments'] = data['COMMENTS'].apply(preprocess_text_function) # apply preprocess_text_function to each row in data['COMMENTS']\n",
    "print(data['COMMENTS'].apply(preprocess_text_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\OneDrive - Tunku Abdul Rahman University College\\Software Engineering\\Year 2\\Sem 3\\AI\\NLP-Assignment\\AI-Assignment-NLP.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sentiment\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# apply get_sentiment function\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/OneDrive%20-%20Tunku%20Abdul%20Rahman%20University%20College/Software%20Engineering/Year%202/Sem%203/AI/NLP-Assignment/AI-Assignment-NLP.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mCOMMENTS\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(get_sentiment)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# create get_sentiment function\n",
    "\n",
    "def get_sentiment(text):\n",
    "\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    sentiment = 1 if scores['pos'] > 0 else 0\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "# apply get_sentiment function\n",
    "\n",
    "data['sentiment'] = data['COMMENTS'].apply(get_sentiment)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
